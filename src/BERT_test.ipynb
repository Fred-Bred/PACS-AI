{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\frbre\\OneDrive\\01 Dokumenter\\01 Uni\\SDS Thesis\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "# import sys\n",
    "# sys.path.append(r\".\\src\\utils\")\n",
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import utils.model as model\n",
    "from utils.transcript import *\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fake data\n",
    "create_random_word_document(r'C:\\Users\\frbre\\OneDrive\\01 Dokumenter\\01 Uni\\SDS Thesis\\data\\Word_test\\random_test_A.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "path_A = r\"C:\\Users\\frbre\\OneDrive\\01 Dokumenter\\01 Uni\\SDS Thesis\\data\\Word_test\\Lorem ipsum_A.docx\"\n",
    "path_B = \"C:/Users/frbre/OneDrive/01 Dokumenter/01 Uni/SDS Thesis/data/Word_test/Lorem ipsum_B.docx\"\n",
    "path_C = \"C:/Users/frbre/OneDrive/01 Dokumenter/01 Uni/SDS Thesis/data/Word_test/Lorem ipsum dolor_C.docx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load paragraphs with comments\n",
    "ref_doc_A = comments_with_reference_paragraph(path_A)\n",
    "ref_doc_B = comments_with_reference_paragraph(path_B)\n",
    "ref_doc_C = comments_with_reference_paragraph(path_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences, labels = map(list, zip(*ref_doc_A))\n",
    "sentences, labels = extract_text_and_comments([ref_doc_A, ref_doc_B, ref_doc_C], as_lists=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['35'],\n",
       " ['02'],\n",
       " ['28'],\n",
       " ['04'],\n",
       " ['08'],\n",
       " ['11'],\n",
       " ['25'],\n",
       " ['01'],\n",
       " ['34'],\n",
       " ['17'],\n",
       " ['15'],\n",
       " ['06'],\n",
       " ['21'],\n",
       " ['29', '31'],\n",
       " ['22']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect labels\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nullam vehicula tellus ut sem rhoncus sodales. Mauris porta ultricies ligula, sit amet placerat diam tristique nec. Nullam id orci efficitur justo fringilla malesuada in eu tortor. Maecenas lectus sem, porta in sapien vel, finibus dictum tellus. Pellentesque aliquam elit in tellus efficitur rhoncus. Integer id lacinia nisi, non elementum quam. Proin eros nunc, aliquet eget blandit in, efficitur et lacus. Mauris egestas ultrices lacus sit amet consectetur. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc at diam quis nulla rhoncus aliquet. Suspendisse in elit non nibh porttitor gravida nec eget velit. Etiam rutrum bibendum nulla, vel pellentesque sem. Vivamus aliquet vitae ipsum ut auctor. Vestibulum bibendum condimentum turpis sit amet laoreet. Nunc fermentum blandit sapien, sed pulvinar lorem laoreet id. Suspendisse vitae sagittis dolor, a viverra turpis. ',\n",
       " 'Sed tristique at neque ut porttitor. Nullam ut mollis arcu. Aenean eget ex placerat, pellentesque lorem vitae, pharetra diam. Donec auctor felis nec sodales viverra. Fusce hendrerit vestibulum ante, eu mattis sapien porttitor ornare. Sed vehicula augue quis bibendum accumsan. Interdum et malesuada fames ac ante ipsum primis in faucibus. Vivamus sed ligula ut quam fringilla finibus ut in nisl. Nunc maximus lorem ac urna venenatis, viverra consectetur arcu aliquam. Maecenas lorem felis, dignissim pretium lobortis eget, convallis vitae est. Vestibulum egestas nisl mauris. Suspendisse ullamcorper, neque nec volutpat rutrum, nisi erat volutpat nisi, sit amet consequat quam metus vel nisi. Phasellus ac ex dui. ',\n",
       " 'Nulla facilisi. Donec eu tellus nunc. In pellentesque, tellus at ullamcorper ultricies, odio ex sodales est, nec laoreet enim neque non justo. Curabitur cursus vel tortor congue posuere. Donec condimentum auctor pulvinar. Nunc nec cursus quam. Ut congue dui aliquet semper porta. Mauris vitae tellus metus. Nullam sed augue sed tellus tristique dapibus. Nulla suscipit purus enim, in auctor libero gravida ac. Etiam semper massa at eros luctus, at tincidunt libero dictum. ',\n",
       " 'Sed rutrum, eros quis tempus luctus, magna neque tempus magna, nec scelerisque tortor erat non lectus. Mauris sit amet tellus mauris. Nunc ex lorem, cursus et leo eu, posuere vulputate enim. Quisque placerat ut nibh ut tincidunt. Donec nunc sem, ultrices in dui vitae, ornare volutpat erat. Sed dictum ligula in metus ultrices, vitae pretium erat vestibulum. Cras at euismod odio, at tincidunt nisl. Morbi nulla nibh, finibus sed consequat quis, dignissim ac turpis. Integer vulputate ex id velit tincidunt posuere. Duis pulvinar, risus ac ultricies lacinia, augue ligula varius sem, sed ultrices mauris lacus id sem. Cras placerat elit a convallis aliquet. Duis egestas faucibus orci, vel venenatis eros suscipit eu. Quisque laoreet leo nec metus eleifend, viverra tempus dolor euismod. Nulla et consectetur lacus, nec venenatis velit. Pellentesque turpis orci, tempor in augue sed, malesuada aliquam tellus. Vivamus faucibus libero eu ligula convallis mattis. ',\n",
       " 'Lorem ipsum dolor sit amet, consectetur adipiscing elit. Donec at molestie nisl, malesuada tempus lectus. Mauris feugiat rutrum mauris, in dictum est volutpat a. Pellentesque dictum metus id mi aliquam ultrices. Donec nec est et magna mollis consectetur. Sed tincidunt magna in enim efficitur ullamcorper. Proin facilisis eleifend urna, eget fermentum odio eleifend a. Integer molestie facilisis nulla vitae mattis. Cras non pretium arcu. Nulla facilisi. Morbi quis commodo libero. ',\n",
       " 'Cras mattis ipsum ac nisi suscipit, quis semper lectus porta. Aliquam erat volutpat. Quisque ac sem tempor mauris hendrerit consectetur. Vestibulum volutpat lorem vel nisi ullamcorper semper. Vestibulum eget tortor a ligula semper rhoncus non ut sem. Curabitur scelerisque mollis euismod. In interdum laoreet purus ut sollicitudin. Phasellus ut tempor dolor. Interdum et malesuada fames ac ante ipsum primis in faucibus. Nam interdum lacus sed mi dictum euismod. ',\n",
       " 'Aliquam ac mauris eu est dapibus imperdiet quis ac nisi. Ut faucibus pharetra est eget porttitor. Vestibulum quis dapibus purus, vitae euismod est. Pellentesque molestie turpis enim, vitae aliquam ligula auctor nec. Maecenas dui nisi, varius eget convallis eget, gravida a est. Aliquam vel libero non lectus rhoncus imperdiet. Mauris fringilla magna ullamcorper enim cursus rutrum. In augue enim, ultricies in laoreet tincidunt, condimentum eu enim. Cras feugiat rutrum consectetur. Suspendisse potenti. Fusce dignissim magna vehicula magna mollis, eget fermentum libero pretium. Fusce mattis sit amet nulla id tempor. Mauris fermentum efficitur accumsan. Duis eu iaculis mi. ',\n",
       " 'Morbi ultricies luctus arcu in maximus. Sed ac turpis eu est efficitur scelerisque in sed elit. Vestibulum fringilla justo sapien, eu facilisis neque eleifend id. Quisque vel ante condimentum dolor scelerisque gravida. Interdum et malesuada fames ac ante ipsum primis in faucibus. Sed ultricies ipsum a justo volutpat, quis laoreet tellus venenatis. Aenean leo erat, blandit suscipit turpis quis, feugiat cursus eros. Fusce laoreet nibh libero, in interdum lacus aliquet eu. Fusce at pretium dolor. ',\n",
       " 'In lacinia risus ac lacus lobortis, vel dapibus eros consectetur. Etiam lobortis ex ac risus luctus scelerisque. Proin vel purus tempor, bibendum diam at, rhoncus elit. Vivamus vitae ex quis nunc consequat dictum condimentum ac urna. Pellentesque eu arcu at tortor consequat tristique. Nullam sagittis semper felis at interdum. Quisque finibus id quam at ultrices. Praesent vel odio purus. Cras id consequat dolor, eu ullamcorper leo. ',\n",
       " 'Sed porttitor dui non massa interdum placerat. Etiam iaculis est eu sapien sollicitudin condimentum. Sed et velit neque. Nunc at aliquam orci, et volutpat lorem. Nulla semper vel nibh sit amet tempor. Phasellus dapibus arcu quis ultricies bibendum. Quisque nulla ligula, fringilla vitae lacus ac, tincidunt tincidunt tellus. Phasellus consectetur accumsan iaculis. Phasellus semper ipsum sed lorem ultricies elementum. Aenean vestibulum urna condimentum ex bibendum, a maximus quam semper. Quisque dui eros, pretium non facilisis non, fermentum suscipit dolor. Nulla pharetra aliquet tortor quis accumsan. ',\n",
       " 'Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean scelerisque libero neque, quis molestie odio imperdiet interdum. Aliquam ac arcu congue, scelerisque mi eget, ornare mi. Nunc arcu libero, commodo tempus blandit quis, cursus pellentesque dui. Phasellus nibh nunc, dignissim in maximus vel, rhoncus vitae dui. Maecenas ornare ut nulla dapibus sollicitudin. Morbi molestie risus nec ligula accumsan, gravida iaculis diam feugiat. Donec quis arcu id nunc vulputate ultrices id in leo. Sed aliquet, ligula vitae congue placerat, ex erat consequat dolor, et rhoncus dolor lacus tincidunt metus. Etiam commodo, neque a aliquam tempus, tellus ipsum varius odio, at laoreet urna tortor vitae tellus. Aliquam dignissim mauris sed elit euismod, eu pharetra magna aliquet. Interdum et malesuada fames ac ante ipsum primis in faucibus. Cras in nisl vestibulum, varius lorem ac, mollis ex. ',\n",
       " 'Nunc a lectus eget justo pretium ultricies. Donec vitae tellus elementum, tempor est id, feugiat odio. Sed nulla orci, sollicitudin sed metus quis, aliquet vehicula ex. In eu vestibulum felis, non semper purus. Sed ultricies interdum dui, eget laoreet nunc maximus sodales. Proin lectus ante, auctor id bibendum nec, cursus ac mauris. Suspendisse et placerat est, ut accumsan odio. ',\n",
       " 'Cras eget ullamcorper lacus. Donec a vestibulum enim. Aenean a ante quam. Vestibulum tincidunt dui eget massa fringilla pretium. Etiam faucibus pulvinar congue. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Fusce ex mi, sagittis at rutrum id, placerat ac nisi. ',\n",
       " 'In a euismod nunc. Phasellus commodo iaculis elit eget rutrum. Nulla diam diam, facilisis vel dolor ac, bibendum condimentum augue. Integer a ultrices lacus, non lobortis justo. Nunc elementum nec nisi id ornare. Nullam eleifend pharetra tortor id tempor. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. Nam ac maximus quam, id semper leo. Nam sed hendrerit tortor, eu molestie purus. Etiam in finibus nulla. Ut quis feugiat neque. Praesent molestie lorem augue, ac tincidunt velit auctor sed. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Ut sed elit et dui maximus molestie. ',\n",
       " 'Donec viverra metus ac orci aliquet pellentesque. Mauris nec velit quis odio venenatis pharetra. Nulla tincidunt nisl tristique finibus sagittis. In aliquet elit enim, sit amet efficitur nibh pellentesque vel. Praesent cursus magna tincidunt dolor mollis, nec venenatis ex volutpat. Nullam at lorem lectus. Mauris eros est, suscipit eget commodo id, dapibus nec massa. Suspendisse cursus accumsan lacus, et fringilla ipsum vestibulum nec. Donec odio quam, porta eget leo sit amet, commodo tempor massa. Aenean vulputate molestie tincidunt. Quisque quis convallis risus, sed lacinia nisi. Integer ut turpis ullamcorper, pulvinar sapien in, pharetra lectus. Integer nec congue ante. Integer et tellus nec velit iaculis maximus sit amet ut nulla. Maecenas ullamcorper congue sapien sed varius. Pellentesque ut consequat magna, luctus faucibus velit. ']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect sentences\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>04</th>\n",
       "      <th>06</th>\n",
       "      <th>08</th>\n",
       "      <th>11</th>\n",
       "      <th>15</th>\n",
       "      <th>17</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>25</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>31</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lorem ipsum dolor sit amet, consectetur adipis...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sed tristique at neque ut porttitor. Nullam ut...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nulla facilisi. Donec eu tellus nunc. In pelle...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sed rutrum, eros quis tempus luctus, magna neq...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lorem ipsum dolor sit amet, consectetur adipis...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cras mattis ipsum ac nisi suscipit, quis sempe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Aliquam ac mauris eu est dapibus imperdiet qui...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Morbi ultricies luctus arcu in maximus. Sed ac...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>In lacinia risus ac lacus lobortis, vel dapibu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sed porttitor dui non massa interdum placerat....</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Lorem ipsum dolor sit amet, consectetur adipis...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Nunc a lectus eget justo pretium ultricies. Do...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Cras eget ullamcorper lacus. Donec a vestibulu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>In a euismod nunc. Phasellus commodo iaculis e...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Donec viverra metus ac orci aliquet pellentesq...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentences  01  02  04  06  08  11  \\\n",
       "0   Lorem ipsum dolor sit amet, consectetur adipis...   0   0   0   0   0   0   \n",
       "1   Sed tristique at neque ut porttitor. Nullam ut...   0   1   0   0   0   0   \n",
       "2   Nulla facilisi. Donec eu tellus nunc. In pelle...   0   0   0   0   0   0   \n",
       "3   Sed rutrum, eros quis tempus luctus, magna neq...   0   0   1   0   0   0   \n",
       "4   Lorem ipsum dolor sit amet, consectetur adipis...   0   0   0   0   1   0   \n",
       "5   Cras mattis ipsum ac nisi suscipit, quis sempe...   0   0   0   0   0   1   \n",
       "6   Aliquam ac mauris eu est dapibus imperdiet qui...   0   0   0   0   0   0   \n",
       "7   Morbi ultricies luctus arcu in maximus. Sed ac...   1   0   0   0   0   0   \n",
       "8   In lacinia risus ac lacus lobortis, vel dapibu...   0   0   0   0   0   0   \n",
       "9   Sed porttitor dui non massa interdum placerat....   0   0   0   0   0   0   \n",
       "10  Lorem ipsum dolor sit amet, consectetur adipis...   0   0   0   0   0   0   \n",
       "11  Nunc a lectus eget justo pretium ultricies. Do...   0   0   0   1   0   0   \n",
       "12  Cras eget ullamcorper lacus. Donec a vestibulu...   0   0   0   0   0   0   \n",
       "13  In a euismod nunc. Phasellus commodo iaculis e...   0   0   0   0   0   0   \n",
       "14  Donec viverra metus ac orci aliquet pellentesq...   0   0   0   0   0   0   \n",
       "\n",
       "    15  17  21  22  25  28  29  31  34  35  \n",
       "0    0   0   0   0   0   0   0   0   0   1  \n",
       "1    0   0   0   0   0   0   0   0   0   0  \n",
       "2    0   0   0   0   0   1   0   0   0   0  \n",
       "3    0   0   0   0   0   0   0   0   0   0  \n",
       "4    0   0   0   0   0   0   0   0   0   0  \n",
       "5    0   0   0   0   0   0   0   0   0   0  \n",
       "6    0   0   0   0   1   0   0   0   0   0  \n",
       "7    0   0   0   0   0   0   0   0   0   0  \n",
       "8    0   0   0   0   0   0   0   0   1   0  \n",
       "9    0   1   0   0   0   0   0   0   0   0  \n",
       "10   1   0   0   0   0   0   0   0   0   0  \n",
       "11   0   0   0   0   0   0   0   0   0   0  \n",
       "12   0   0   1   0   0   0   0   0   0   0  \n",
       "13   0   0   0   0   0   0   1   1   0   0  \n",
       "14   0   0   0   1   0   0   0   0   0   0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = extract_text_and_comments([ref_doc_A, ref_doc_B, ref_doc_C], as_lists=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_array = df.iloc[:, 1:].to_numpy()\n",
    "sentences = df[\"sentences\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create array of subclasses\n",
    "# Define the conditions and corresponding values for replacement\n",
    "conditions = [\n",
    "    (code_array >= 1) & (code_array <= 10),\n",
    "    (code_array >= 11) & (code_array <= 15),\n",
    "    (code_array >= 16) & (code_array <= 24),\n",
    "    (code_array >= 25) & (code_array <= 38),\n",
    "    (code_array >= 39) & (code_array <= 50)\n",
    "]\n",
    "values = [1, 2, 3, 4, 5]\n",
    "\n",
    "# Replace the values in code_array based on the conditions\n",
    "label_array = np.select(conditions, values)\n",
    "\n",
    "label_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', max_length=512, padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nullam vehicula tellus ut sem rhoncus sodales. Mauris porta ultricies ligula, sit amet placerat diam tristique nec. Nullam id orci efficitur justo fringilla malesuada in eu tortor. Maecenas lectus sem, porta in sapien vel, finibus dictum tellus. Pellentesque aliquam elit in tellus efficitur rhoncus. Integer id lacinia nisi, non elementum quam. Proin eros nunc, aliquet eget blandit in, efficitur et lacus. Mauris egestas ultrices lacus sit amet consectetur. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc at diam quis nulla rhoncus aliquet. Suspendisse in elit non nibh porttitor gravida nec eget velit. Etiam rutrum bibendum nulla, vel pellentesque sem. Vivamus aliquet vitae ipsum ut auctor. Vestibulum bibendum condimentum turpis sit amet laoreet. Nunc fermentum blandit sapien, sed pulvinar lorem laoreet id. Suspendisse vitae sagittis dolor, a viverra turpis. \n",
      "Token IDs: [101, 91473, 10451, 177, 13221, 10465, 66800, 19285, 10392, 10308, 117, 10173, 104380, 43745, 10129, 10840, 17437, 10291, 19113, 18166, 10123, 119, 28336, 11083, 10147, 10323, 39187, 13313, 41549, 10251, 11735, 11531, 186, 19792, 14319, 10380, 22508, 10107, 119, 103722, 12125, 17953, 16600, 80576, 10171, 69751, 13313, 117, 19285, 10392, 10308, 106742, 10526, 10671, 10147, 15633, 44039, 10554, 10350, 119, 28336, 11083, 10147, 12604, 10345, 10598, 56331, 110284, 10546, 81049, 35350, 31681, 11083, 24617, 82810, 10106, 14444, 10114, 36396, 10129, 119, 13240, 101948, 30988, 12280, 11531, 117, 17953, 10106, 82427, 11540, 21861, 117, 59222, 13763, 10120, 95745, 41549, 10251, 119, 75056, 44991, 10171, 11189, 12134, 65137, 18166, 10123, 10106, 41549, 10251, 56331, 110284, 10546, 186, 19792, 14319, 119, 81687, 95609, 12604, 23455, 56665, 10414, 10449, 117, 10446, 87573, 10147, 29153, 119, 14021, 10245, 10163, 10310, 11715, 10350, 117, 12134, 27579, 32551, 17805, 10486, 10106, 117, 56331, 110284, 10546, 10131, 23455, 10251, 119, 103722, 12125, 173, 63952, 10403, 16600, 20416, 10107, 23455, 10251, 19285, 10392, 10308, 10173, 104380, 43745, 10129, 119, 91473, 10451, 177, 13221, 10465, 66800, 19285, 10392, 10308, 117, 10173, 104380, 43745, 10129, 10840, 17437, 10291, 19113, 18166, 10123, 119, 34289, 10350, 10160, 10671, 10147, 10355, 10107, 60589, 186, 19792, 14319, 12134, 27579, 119, 21241, 63592, 28169, 10106, 18166, 10123, 10446, 10414, 39554, 16874, 95285, 10129, 91878, 10229, 10554, 10350, 32551, 21861, 10486, 119, 16232, 26418, 13483, 58679, 11342, 10965, 27983, 60589, 117, 21861, 100361, 14467, 11189, 11531, 119, 43194, 13527, 12134, 27579, 13952, 10112, 177, 13221, 10465, 11735, 10257, 21038, 119, 39669, 91610, 20571, 11342, 10965, 27983, 10173, 45094, 45610, 10147, 32461, 16825, 19285, 10392, 10308, 58039, 29711, 10123, 119, 34289, 10350, 50755, 40468, 10147, 17805, 10486, 82427, 11540, 117, 38559, 34597, 56963, 39735, 97869, 10147, 58039, 29711, 10123, 12604, 119, 21241, 63592, 28169, 13952, 10112, 10148, 78108, 10291, 66800, 117, 169, 26309, 21084, 32461, 16825, 119, 102]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize texts and map the tokens to their word IDs.\n",
    "input_ids = []\n",
    "\n",
    "for sent in sentences:\n",
    "    encoded_text = tokenizer.encode(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                   )\n",
    "    input_ids.append(encoded_text)\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', sentences[0])\n",
    "print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  326\n"
     ]
    }
   ],
   "source": [
    "# Check max sentence length\n",
    "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pad our input tokens\n",
    "input_ids = keras.preprocessing.sequence.pad_sequences(input_ids, maxlen=512, dtype=\"long\", truncating=\"post\", padding=\"post\", value=0)\n",
    "\n",
    "# Create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "for sent in input_ids:\n",
    "    \n",
    "    # Create the attention mask.\n",
    "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
    "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "    \n",
    "    # Store the attention mask for this sentence.\n",
    "    attention_masks.append(att_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make train/val split\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, label_array, \n",
    "                                                            random_state=2018, test_size=0.1)\n",
    "# Performing same steps on the attention masks\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, label_array,\n",
    "                                             random_state=2018, test_size=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensors\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 2\n",
    "\n",
    "# Create the DataLoader for our training set.\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras BERT model\n",
    "keras_model = model.BERTKeras(num_classes=5, hidden_size=768, dropout_prob=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"bert_keras_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"bert_keras_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">    Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ torch_module_wrapper_1          │ ?                         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">177,853,4…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TorchModuleWrapper</span>)            │                           │            │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│                                 │                           │  (unbuilt) │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│                                 │                           │  (unbuilt) │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│                                 │                           │  (unbuilt) │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│                                 │                           │  (unbuilt) │\n",
       "└─────────────────────────────────┴───────────────────────────┴────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ torch_module_wrapper_1          │ ?                         │ \u001b[38;5;34m177,853,4…\u001b[0m │\n",
       "│ (\u001b[38;5;33mTorchModuleWrapper\u001b[0m)            │                           │            │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                         │          \u001b[38;5;34m0\u001b[0m │\n",
       "│                                 │                           │  (unbuilt) │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                         │          \u001b[38;5;34m0\u001b[0m │\n",
       "│                                 │                           │  (unbuilt) │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                         │          \u001b[38;5;34m0\u001b[0m │\n",
       "│                                 │                           │  (unbuilt) │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                         │          \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                         │          \u001b[38;5;34m0\u001b[0m │\n",
       "│                                 │                           │  (unbuilt) │\n",
       "└─────────────────────────────────┴───────────────────────────┴────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">177,853,440</span> (678.46 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m177,853,440\u001b[0m (678.46 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">177,853,440</span> (678.46 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m177,853,440\u001b[0m (678.46 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test run\n",
    "result = keras_model(train_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 512, 5])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"bert_keras_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"bert_keras_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">    Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ torch_module_wrapper_1          │ ?                         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">177,853,4…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TorchModuleWrapper</span>)            │                           │            │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                         │    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,592</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                         │    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,592</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                         │    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,592</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,845</span> │\n",
       "└─────────────────────────────────┴───────────────────────────┴────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ torch_module_wrapper_1          │ ?                         │ \u001b[38;5;34m177,853,4…\u001b[0m │\n",
       "│ (\u001b[38;5;33mTorchModuleWrapper\u001b[0m)            │                           │            │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                         │    \u001b[38;5;34m590,592\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                         │    \u001b[38;5;34m590,592\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                         │    \u001b[38;5;34m590,592\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                         │          \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                         │      \u001b[38;5;34m3,845\u001b[0m │\n",
       "└─────────────────────────────────┴───────────────────────────┴────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">179,629,061</span> (685.23 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m179,629,061\u001b[0m (685.23 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,775,621</span> (6.77 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,775,621\u001b[0m (6.77 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">177,853,440</span> (678.46 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m177,853,440\u001b[0m (678.46 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Layers are 'unbuilt' until they are called\n",
    "# After calling the model, it looks like this\n",
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_model = model.BERTTorch(num_classes=5, hidden_size=768, dropout_prob=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTTorch(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (fc1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (fc2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (fc3): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (output_layer): Linear(in_features=768, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(torch_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_result = torch_model(train_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 512, 5])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_result.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
